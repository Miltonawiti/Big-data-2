{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef1b1534-c406-4b7f-90b9-3b00e43ddffc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, mean\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "import time\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Mental Health Analysis with Spark ML\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Step 1: Load and preprocess data\n",
    "# Load the CSV file\n",
    "df = spark.read.csv(\"/opt/spark/mental_health_dataset.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Convert columns to appropriate data types\n",
    "df = df.withColumn(\"Age\", col(\"Age\").cast(\"int\")) \\\n",
    "       .withColumn(\"Gender\", col(\"Gender\").cast(\"string\")) \\\n",
    "       .withColumn(\"self_employed\", col(\"self_employed\").cast(\"string\")) \\\n",
    "       .withColumn(\"family_history\", col(\"family_history\").cast(\"string\")) \\\n",
    "       .withColumn(\"treatment\", col(\"treatment\").cast(\"string\")) \\\n",
    "       .withColumn(\"work_interfere\", col(\"work_interfere\").cast(\"string\")) \\\n",
    "       .withColumn(\"no_employees\", col(\"no_employees\").cast(\"string\"))\n",
    "\n",
    "# Index categorical columns\n",
    "categorical_columns = [\"Gender\", \"self_employed\", \"family_history\", \"treatment\", \"work_interfere\", \"no_employees\"]\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\") for column in categorical_columns]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df = pipeline.fit(df).transform(df)\n",
    "\n",
    "# Assemble feature vector\n",
    "feature_columns = [col + \"_index\" for col in categorical_columns if col + \"_index\" in df.columns] + [\"Age\"]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "data = assembler.transform(df).select(\"features\", \"treatment_index\")\n",
    "\n",
    "# Rename target column\n",
    "data = data.withColumnRenamed(\"treatment_index\", \"target\")\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Step 2: Initialize the RandomForestClassifier for classification\n",
    "rf = RandomForestClassifier(labelCol=\"target\", featuresCol=\"features\", numTrees=50)\n",
    "\n",
    "# Step 3: Train the model\n",
    "start_time = time.time()\n",
    "rf_model = rf.fit(train_data)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Training Time: {train_time} seconds\")\n",
    "\n",
    "# Step 4: Predict and evaluate on the test set\n",
    "predictions = rf_model.transform(test_data)\n",
    "\n",
    "# Step 5: Evaluate model performance metrics\n",
    "# Accuracy\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"target\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "\n",
    "# AUC\n",
    "evaluator_auc = BinaryClassificationEvaluator(labelCol=\"target\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator_auc.evaluate(predictions)\n",
    "\n",
    "# Precision and Recall\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"target\", metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"target\", metricName=\"weightedRecall\")\n",
    "precision = evaluator_precision.evaluate(predictions)\n",
    "recall = evaluator_recall.evaluate(predictions)\n",
    "\n",
    "# Print Evaluation Metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"AUC: {auc}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8677b95e-01af-41d2-9799-1f77d8d3dc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
